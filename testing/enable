from databricks.sdk import WorkspaceClient
import databricks.sdk.service.catalog as c

vsc = VectorSearchClient(disable_notice=True)

TABLE_NAME_RAG_VSI = "sample_naveen_rag_vsi"

source_table_name = f"{CATALOG}.{SCHEMA_NAME}.{TABLE_NAME}"
vsi_index_name = f"{CATALOG}.{SCHEMA_NAME}.{TABLE_NAME_RAG_VSI}"

def index_exists(vsc, endpoint_name, index_name):
    """
    Checks if a vector search index exists on the given endpoint.
    """
    try:
        idx = vsc.get_index(index_name)
        if idx['endpoint_name'] == endpoint_name:
            return True
        else:
            return False
    except Exception as e:
        return False


# create or sync the index
if not index_exists(vsc, ENDPOINT_NAME, vsi_index_name):
    print(f"Creating index {vsi_index_name} on endpoint {ENDPOINT_NAME}...")
    vsc.create_delta_sync_index(
        endpoint_name = ENDPOINT_NAME,
        index_name = vsi_index_name,
        source_table_name = source_table_name,
        pipeline_type = "TRIGGERED",
        primary_key = "chunk_id",
        embedding_vector_column = "embeddings_array",
        embedding_dimension = 1024
    )
else:
    vsc.get_index(vsi_index_name).sync()  # Fixed: use vsi_index_name, not endpoint_name



import mlflow.deployments

deploy_client = mlflow.deployments.get_deploy_client("databricks")

user_query = "What is the purchase number of alice and where does he live ?"

response = deploy_client.predict(endpoint= EMBEDDINGS_ENDPOINT, inputs = {"input": [user_query]})
embeddings = [e['embedding'] for e in response.data]
print(embeddings)



results = vsc.get_index(endpoint_name=ENDPOINT_NAME, index_name=vsi_index_name).similarity_search(
    query_vector = embeddings[0],
    columns=["chunk_text","file_name","chunk_id"],
    num_results = 3)

passages = []
for doc in results.get('result',{}).get('data_array', []):
    new_doc = {"file": doc[1], "text": doc[0], "chunk_id": doc[2], "score": doc[3]}
    passages.append(new_doc)
pprint.pprint(passages)
